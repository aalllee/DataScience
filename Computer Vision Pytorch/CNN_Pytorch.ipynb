{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443b6524-05f0-4a85-b043-128d7ff5a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371bf20d-dde4-4349-ad11-28b07509e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381fa53d-2cb0-4e6c-bbef-d51e8306690b",
   "metadata": {},
   "source": [
    "PyTorch expects the input to be of the shape N x C x H x W, where N is the number (batch size) of images, C is the number of channels, H is the height, and W is the width of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008255e7-da08-4ad5-9920-3c6285afa88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two data points, where each is 4 x 4 in shape and has 1 channel.\n",
    "X_train = torch.tensor([[[[1,2,3,4],[2,3,4,5],\n",
    "                          [5,6,7,8],[1,3,4,5]]],\n",
    "                        [[[-1,2,3,-4],[2,-3,4,5],\n",
    "            [-5,6,-7,8],[-1,-3,-4,-5]]]]).to(device).float()\n",
    "X_train /= 8\n",
    "y_train = torch.tensor([0,1]).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807e92e7-c59f-4713-9eb4-f922f24154fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0be61b9-1ab1-4239-8d88-4e4a92e77968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "                nn.Conv2d(1, 1, kernel_size=3), \n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(1, 1),\n",
    "                nn.Sigmoid(),\n",
    "            ).to(device)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e24557a-4ce8-49f5-bf05-8d4c834e6d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_summary\n",
      "  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\n",
      "Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: torch_summary\n",
      "Successfully installed torch_summary-1.4.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 1, 2, 2]             10\n",
      "├─MaxPool2d: 1-2                         [-1, 1, 1, 1]             --\n",
      "├─ReLU: 1-3                              [-1, 1, 1, 1]             --\n",
      "├─Flatten: 1-4                           [-1, 1]                   --\n",
      "├─Linear: 1-5                            [-1, 1]                   2\n",
      "├─Sigmoid: 1-6                           [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_summary\n",
    "from torchsummary import summary\n",
    "model, loss_fn, optimizer = get_model()\n",
    "summary(model, X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db49852c-8c34-4e08-accd-8cf6974de6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x,y,model,opt,loss_fn):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction.squeeze(0),y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3406a709-227c-4a0b-9083-bad7674e2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(TensorDataset(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffce7c83-d200-46e7-97cd-56a2d7d2f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2000):\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, model,optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "560f57b7-6a10-4588-a904-16b8b44b0af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1302]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2064779-e4f6-4415-9265-370bed1b0da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
