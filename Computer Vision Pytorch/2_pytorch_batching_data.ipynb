{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc392dd5-5d4c-4608-946f-a9ad56f7844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2c29e-bf16-47f8-95a6-9843243d7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES ON GRADIENT COMPUTATION USING BATCH DATA AS AN INPUT\n",
    "\"\"\"\n",
    "During training, a batch of data is passed through the model,\n",
    "which produces predictions for each item in the batch.\n",
    "The loss is then calculated by comparing these predictions to the\n",
    "target values for each data pointin the batch, resulting in a vector of individual losses.\n",
    "This vector is usually averaged or summed to get a single scalar loss for the entire batch.\n",
    "When .backward() is called on this scalar loss, the gradients are computed with respect to\n",
    "each model parameter, based on the averaged (or summed) loss for the batch. This gives the\n",
    "gradient of the batch loss with respect to each parameter.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
